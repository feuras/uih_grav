#!/usr/bin/env python3
"""
UIH Fisher halo fitting suite for SPARC rotation curve data.

Input:
  - Directory data/sparc_npz containing galaxy_*.npz files produced by
    53_build_sparc_npz_from_csv.py. Each file must contain:
        R            [kpc]
        v_obs        [km/s]
        err_v_obs    [km/s]
        v_baryon     [km/s]
    and may contain:
        distance_Mpc
        galaxy_name

Output:
  - results/fisher_sparc/fisher_sparc_summary.json
  - results/fisher_sparc/fisher_sparc_summary.csv
  - results/fisher_sparc/rar_all.npy
  - results/fisher_sparc/rar_<galaxy>.npy   (per galaxy RAR triplets)
"""

import csv
import json
import math
import multiprocessing as mp
from pathlib import Path
from typing import Dict, List

import numpy as np


# Directories
DATA_DIR = Path("data") / "sparc_npz"
OUT_DIR = Path("results") / "fisher_sparc"


# =========================
#  UIH halo helpers
# =========================

def compute_baryonic_mass_profile(R_kpc: np.ndarray, v_baryon_kms: np.ndarray) -> np.ndarray:
    """
    Code unit baryonic mass profile M_b(R) from the baryonic rotation curve.

    In the gravity paper units one effectively has G = 1 so that

        v_c(R)**2 = M(R) / R,

    hence

        M_b(R) = v_b(R)**2 * R.

    Here we treat R in kpc and v in km/s as code units. Any global scale factor
    is absorbed into the fitted amplitude A.
    """
    return v_baryon_kms**2 * R_kpc


def compute_g_baryon(R_kpc: np.ndarray, v_baryon_kms: np.ndarray) -> np.ndarray:
    """
    Code unit baryonic acceleration g_b(R) consistent with

        v_b(R)**2 = g_b(R) * R.
    """
    R_safe = np.maximum(R_kpc, 1.0e-6)
    return v_baryon_kms**2 / R_safe


def compute_g_base_halo(
    R_kpc: np.ndarray,
    M_b: np.ndarray,
    R_cut_kpc: float,
) -> np.ndarray:
    """
    Base halo acceleration profile g_base(R) for A = 1, following the Fisher scalar halo.

    In code units (G = 1) the Fisher halo mass generated by the scalar mode is

        M_grad(R) = ∫_0^R alpha(r) M_b(r)**2 / r**2 dr,

    and the corresponding halo acceleration is

        g_h(R) = M_grad(R) / R**2.

    We implement the RG inspired piecewise coupling

        alpha(r) ∝ (r / R_cut)**2   for r <= R_cut,
        alpha(r) ∝ 1                for r >= R_cut,

    and absorb the global proportionality constant into the fitted amplitude A.
    """
    R_cut = max(float(R_cut_kpc), 1.0e-6)
    R = R_kpc

    # Piecewise coupling shape alpha_shape(r)
    x = R / R_cut
    alpha_shape = np.where(R <= R_cut, x**2, 1.0)

    # Integrand for M_grad: f(r) = alpha(r) M_b(r)**2 / r**2
    R_sq_safe = np.maximum(R**2, 1.0e-10)
    f = alpha_shape * (M_b**2) / R_sq_safe

    # Cumulative trapezoidal integration over radius
    I = np.zeros_like(R)
    for i in range(1, len(R)):
        dR = R[i] - R[i - 1]
        I[i] = I[i - 1] + 0.5 * (f[i] + f[i - 1]) * dR

    # Base halo acceleration (A = 1) is g_base = M_grad / R**2
    g_base = I / R_sq_safe
    return g_base


def chi2_for_A(
    A: float,
    R_kpc: np.ndarray,
    v_obs_kms: np.ndarray,
    err_v_kms: np.ndarray,
    g_b: np.ndarray,
    g_base: np.ndarray,
) -> float:
    """
    Chi squared between model (baryons + A * Fisher halo) and observed rotation curve.

    Model:
        g_tot(R) = g_b(R) + A * g_base(R),
        v_model(R)**2 = g_tot(R) * R.
    """
    g_tot = g_b + A * g_base
    v_model = np.sqrt(np.maximum(g_tot * R_kpc, 0.0))
    sigma2 = np.maximum(err_v_kms, 1.0e-3) ** 2
    return float(np.sum((v_obs_kms - v_model) ** 2 / sigma2))


# =========================
#  Per galaxy fit
# =========================

def fit_single_galaxy(gal_path: Path) -> Dict:
    """
    Fit Fisher halo parameters (A, R_cut) for a single galaxy .npz file.

    Returns a dict with fit summary and writes the galaxy RAR file.
    """
    try:
        data = np.load(gal_path)
    except Exception as e:
        return {
            "name": gal_path.stem,
            "status": f"error_loading_npz:{e}",
        }

    required_keys = ["R", "v_obs", "err_v_obs", "v_baryon"]
    missing = [k for k in required_keys if k not in data]
    if missing:
        return {
            "name": gal_path.stem,
            "status": f"missing_keys:{','.join(missing)}",
        }

    R = np.asarray(data["R"], dtype=float)
    v_obs = np.asarray(data["v_obs"], dtype=float)
    err_v = np.asarray(data["err_v_obs"], dtype=float)
    v_baryon = np.asarray(data["v_baryon"], dtype=float)

    distance_Mpc = float(data["distance_Mpc"]) if "distance_Mpc" in data else float("nan")
    galaxy_name = str(data["galaxy_name"]) if "galaxy_name" in data else gal_path.stem

    # Basic cleaning
    mask = (
        np.isfinite(R)
        & np.isfinite(v_obs)
        & np.isfinite(err_v)
        & np.isfinite(v_baryon)
        & (R > 0.05)
    )

    R = R[mask]
    v_obs = v_obs[mask]
    err_v = err_v[mask]
    v_baryon = v_baryon[mask]

    if len(R) < 4:
        return {
            "name": galaxy_name,
            "status": "too_few_points_after_cleaning",
        }

    # Sort by radius for stable integration
    idx_sort = np.argsort(R)
    R = R[idx_sort]
    v_obs = v_obs[idx_sort]
    err_v = err_v[idx_sort]
    v_baryon = v_baryon[idx_sort]

    R_min = float(np.min(R))
    R_max = float(np.max(R))

    # Baryonic only chi squared
    sigma2 = np.maximum(err_v, 1.0e-3) ** 2
    chi2_baryon = float(np.sum((v_obs - v_baryon) ** 2 / sigma2))

    # Precompute baryonic profiles in code units
    g_b = compute_g_baryon(R, v_baryon)
    M_b = compute_baryonic_mass_profile(R, v_baryon)

    # Grid of RG cutoff radii
    R_cut_grid = np.linspace(0.5 * R_min, 2.0 * R_max, 25)

    best = {
        "chi2": math.inf,
        "A": None,
        "log10A": None,
        "R_cut": None,
    }

    # Search range for amplitude in log10(A)
    logA_lo_global = -6.0
    logA_hi_global = 4.0

    # Golden section constants
    phi = (1.0 + math.sqrt(5.0)) / 2.0
    inv_phi2 = 1.0 / (phi * phi)

    for R_cut in R_cut_grid:
        # Precompute base halo acceleration for this R_cut
        g_base = compute_g_base_halo(R, M_b, R_cut)

        # Golden section over log10(A)
        a = logA_lo_global
        b = logA_hi_global
        h = b - a
        if h <= 1.0e-6:
            continue

        n_iter = 40
        c = a + inv_phi2 * h
        d = b - inv_phi2 * h

        Ac = 10.0 ** c
        Ad = 10.0 ** d
        fc = chi2_for_A(Ac, R, v_obs, err_v, g_b, g_base)
        fd = chi2_for_A(Ad, R, v_obs, err_v, g_b, g_base)

        for _ in range(n_iter):
            if fc < fd:
                b, fd = d, fc
                h = b - a
                d = c
                c = a + inv_phi2 * h
                Ac = 10.0 ** c
                fc = chi2_for_A(Ac, R, v_obs, err_v, g_b, g_base)
            else:
                a, fc = c, fd
                h = b - a
                c = d
                d = b - inv_phi2 * h
                Ad = 10.0 ** d
                fd = chi2_for_A(Ad, R, v_obs, err_v, g_b, g_base)

            if h < 1.0e-3:
                break

        logA_best = 0.5 * (a + b)
        A_best = 10.0 ** logA_best
        chi = chi2_for_A(A_best, R, v_obs, err_v, g_b, g_base)

        if chi < best["chi2"]:
            best["chi2"] = chi
            best["A"] = float(A_best)
            best["log10A"] = float(logA_best)
            best["R_cut"] = float(R_cut)

    if best["A"] is None:
        return {
            "name": galaxy_name,
            "status": "fit_failed_no_minimum",
        }

    # Boundary diagnostics in log space
    A_boundary = "none"
    if best["log10A"] <= logA_lo_global + 1.0e-3:
        A_boundary = "lower"
    elif best["log10A"] >= logA_hi_global - 1.0e-3:
        A_boundary = "upper"

    # Recompute base halo and model velocities for the best parameters
    g_base_best = compute_g_base_halo(R, M_b, best["R_cut"])
    g_h_best = best["A"] * g_base_best
    g_tot_mod = g_b + g_h_best
    v_model_kms = np.sqrt(np.maximum(g_tot_mod * R, 0.0))

    # Build RAR arrays in SI units (m/s^2)
    kpc_to_m = 3.0856775814913673e19
    km_to_m = 1.0e3

    R_m = R * kpc_to_m
    v_obs_mps = v_obs * km_to_m
    v_baryon_mps = v_baryon * km_to_m
    v_mod_mps = v_model_kms * km_to_m

    g_b_si = v_baryon_mps**2 / np.maximum(R_m, 1.0e-3 * kpc_to_m)
    g_tot_obs_si = v_obs_mps**2 / np.maximum(R_m, 1.0e-3 * kpc_to_m)
    g_tot_mod_si = v_mod_mps**2 / np.maximum(R_m, 1.0e-3 * kpc_to_m)

    rar_data = np.stack([g_b_si, g_tot_obs_si, g_tot_mod_si], axis=1)
    rar_path = OUT_DIR / f"rar_{galaxy_name}.npy"
    np.save(rar_path, rar_data)

    return {
        "name": galaxy_name,
        "status": "ok",
        "A": best["A"],
        "log10A": best["log10A"],
        "R_cut": best["R_cut"],
        "chi2": best["chi2"],
        "chi2_baryon": chi2_baryon,
        "A_boundary": A_boundary,
        "N_points": int(len(R)),
        "R_min_kpc": float(R_min),
        "R_max_kpc": float(R_max),
        "distance_Mpc": distance_Mpc,
    }


def _worker(gal_path: Path) -> Dict:
    try:
        return fit_single_galaxy(gal_path)
    except Exception as e:
        return {
            "name": gal_path.stem,
            "status": f"worker_exception:{e}",
        }


# =========================
#  Main orchestration
# =========================

if __name__ == "__main__":
    OUT_DIR.mkdir(parents=True, exist_ok=True)

    gal_files: List[Path] = sorted(DATA_DIR.glob("galaxy_*.npz"))
    if not gal_files:
        print(f"[ERROR] No galaxy_*.npz files found in {DATA_DIR}")
        raise SystemExit(1)

    print(f"[INFO] Found {len(gal_files)} galaxies in {DATA_DIR}")

    cpu_count = mp.cpu_count()
    n_procs = min(22, cpu_count, len(gal_files))
    if n_procs < 1:
        n_procs = 1

    print(f"[INFO] Using {n_procs} process(es) on this run (cpu_count={cpu_count})")

    if n_procs == 1:
        results: List[Dict] = []
        for gf in gal_files:
            r = _worker(gf)
            results.append(r)
            print(f"[GAL] {r.get('name')}: {r.get('status')}")
    else:
        with mp.Pool(processes=n_procs) as pool:
            results = []
            for r in pool.imap_unordered(_worker, gal_files, chunksize=1):
                results.append(r)
                print(f"[GAL] {r.get('name')}: {r.get('status')}")

    # Save JSON summary
    json_path = OUT_DIR / "fisher_sparc_summary.json"
    with open(json_path, "w") as f_json:
        json.dump(results, f_json, indent=2)
    print(f"[INFO] Saved JSON summary to {json_path}")

    # Save CSV summary
    csv_path = OUT_DIR / "fisher_sparc_summary.csv"
    with open(csv_path, "w", newline="") as f_csv:
        writer = csv.writer(f_csv)
        header = [
            "name",
            "status",
            "A",
            "log10A",
            "R_cut_kpc",
            "chi2",
            "chi2_baryon",
            "A_boundary",
            "N_points",
            "R_min_kpc",
            "R_max_kpc",
            "distance_Mpc",
        ]
        writer.writerow(header)
        for r in results:
            writer.writerow([
                r.get("name"),
                r.get("status"),
                r.get("A"),
                r.get("log10A"),
                r.get("R_cut"),
                r.get("chi2"),
                r.get("chi2_baryon"),
                r.get("A_boundary"),
                r.get("N_points"),
                r.get("R_min_kpc"),
                r.get("R_max_kpc"),
                r.get("distance_Mpc"),
            ])
    print(f"[INFO] Saved CSV summary to {csv_path}")

    # Aggregate RAR arrays
    rar_all_list: List[np.ndarray] = []
    for r in results:
        if r.get("status") != "ok":
            continue
        gname = r.get("name")
        rar_file = OUT_DIR / f"rar_{gname}.npy"
        if rar_file.exists():
            rar_all_list.append(np.load(rar_file))

    if rar_all_list:
        rar_all = np.concatenate(rar_all_list, axis=0)
        rar_all_path = OUT_DIR / "rar_all.npy"
        np.save(rar_all_path, rar_all)
        print(f"[INFO] Saved aggregated RAR data to {rar_all_path}")
    else:
        print("[WARN] No successful galaxies for RAR aggregation.")

    # High level summary
    n_total = len(results)
    ok_results = [r for r in results if r.get("status") == "ok"]
    n_ok = len(ok_results)
    n_fail = n_total - n_ok
    print(f"[SUMMARY] Galaxies total: {n_total}, ok: {n_ok}, failed/other: {n_fail}")

    if ok_results:
        A_vals = np.array([r["A"] for r in ok_results], dtype=float)
        logA_vals = np.array([r["log10A"] for r in ok_results], dtype=float)
        Rcut_vals = np.array([r["R_cut"] for r in ok_results], dtype=float)
        chi2_vals = np.array([r["chi2"] for r in ok_results], dtype=float)
        chi2_b_vals = np.array([r["chi2_baryon"] for r in ok_results], dtype=float)
        Npts_vals = np.array([r["N_points"] for r in ok_results], dtype=float)

        dof_fisher = np.maximum(Npts_vals - 2.0, 1.0)
        dof_baryon = np.maximum(Npts_vals, 1.0)

        chi2_red_fisher = chi2_vals / dof_fisher
        chi2_red_baryon = chi2_b_vals / dof_baryon

        def stats(x: np.ndarray):
            return float(np.min(x)), float(np.median(x)), float(np.max(x))

        A_min, A_med, A_max = stats(A_vals)
        logA_min, logA_med, logA_max = stats(logA_vals)
        Rc_min, Rc_med, Rc_max = stats(Rcut_vals)
        c2f_min, c2f_med, c2f_max = stats(chi2_red_fisher)
        c2b_min, c2b_med, c2b_max = stats(chi2_red_baryon)

        print(f"[SUMMARY] A:       min={A_min:.3e}, median={A_med:.3e}, max={A_max:.3e}")
        print(f"[SUMMARY] log10A:  min={logA_min:.2f}, median={logA_med:.2f}, max={logA_max:.2f}")
        print(f"[SUMMARY] R_cut:   min={Rc_min:.2f} kpc, median={Rc_med:.2f} kpc, max={Rc_max:.2f} kpc")
        print(f"[SUMMARY] chi2_red (Fisher):  min={c2f_min:.2f}, median={c2f_med:.2f}, max={c2f_max:.2f}")
        print(f"[SUMMARY] chi2_red (baryon): min={c2b_min:.2f}, median={c2b_med:.2f}, max={c2b_max:.2f}")

        improvement_ratio = chi2_red_baryon / chi2_red_fisher
        n_improve_10 = int(np.sum(improvement_ratio > 1.10))
        n_degrade_10 = int(np.sum(improvement_ratio < 0.90))
        print(f"[SUMMARY] Galaxies with >10 percent chi2_red improvement: {n_improve_10}")
        print(f"[SUMMARY] Galaxies with >10 percent chi2_red worse:      {n_degrade_10}")

        boundaries = [r.get("A_boundary", "none") for r in ok_results]
        n_lower = sum(1 for b in boundaries if b == "lower")
        n_upper = sum(1 for b in boundaries if b == "upper")
        print(f"[SUMMARY] A boundary hits: lower={n_lower}, upper={n_upper}")
